{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>relevance</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>text_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92200</th>\n",
       "      <td>646397350827659264</td>\n",
       "      <td>–ø–æ—Å–≤—è—â–∞—é &lt;NUMBER&gt; @comrinru@tommofuckhazza@ana...</td>\n",
       "      <td>0</td>\n",
       "      <td>–ø–æ—Å–≤—è—â–∞—é  @comrinru@tommofuckhazza@anastasia  ...</td>\n",
       "      <td>[–ø–æ—Å–≤—è—â–∞—é, dash]</td>\n",
       "      <td>dash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92575</th>\n",
       "      <td>846820975069024256</td>\n",
       "      <td>&lt;USER&gt; good evening, ma. couldn't get the fee ...</td>\n",
       "      <td>0</td>\n",
       "      <td>good evening, ma. couldn't get the fee from a...</td>\n",
       "      <td>[good, evening, ma, fee, private, clinic, luth]</td>\n",
       "      <td>good evening ma fee private clinic luth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135022</th>\n",
       "      <td>74285979787202560</td>\n",
       "      <td>&lt;USER&gt; oh, and i need to get some more money \u0001...</td>\n",
       "      <td>0</td>\n",
       "      <td>oh, and i need to get some more money \u0001  that...</td>\n",
       "      <td>[oh, I, need, money, good]</td>\n",
       "      <td>oh I need money good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97707</th>\n",
       "      <td>'348978138795098113'</td>\n",
       "      <td>&lt;HASHTAG&gt; mhflood update - audio director of e...</td>\n",
       "      <td>1</td>\n",
       "      <td>mhflood update - audio director of emergency ...</td>\n",
       "      <td>[mhflood, update, audio, director, emergency, ...</td>\n",
       "      <td>update audio director emergency management sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152965</th>\n",
       "      <td>458355813200183296</td>\n",
       "      <td>people üë´ who are so quick üí®üí® to walk away üêæ &lt;S...</td>\n",
       "      <td>0</td>\n",
       "      <td>people üë´ who are so quick üí®üí® to walk away üêæ  \u0001...</td>\n",
       "      <td>[people, quick, walk, away, intend, stay]</td>\n",
       "      <td>people quick walk away intend stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52628</th>\n",
       "      <td>'324747652124266496'</td>\n",
       "      <td>explosion at texas fertiliser plant: dozens of...</td>\n",
       "      <td>1</td>\n",
       "      <td>explosion at texas fertiliser plant: dozens of...</td>\n",
       "      <td>[explosion, texas, fertiliser, plant, dozen, p...</td>\n",
       "      <td>explosion fertiliser plant people report injur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99608</th>\n",
       "      <td>'348952324741402625'</td>\n",
       "      <td>cleaning your flooded house? tips to stay safe...</td>\n",
       "      <td>1</td>\n",
       "      <td>cleaning your flooded house? tips to stay safe...</td>\n",
       "      <td>[clean, flood, house, tip, stay, safe, healthy...</td>\n",
       "      <td>clean flood house tip stay safe healthy abfloo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65469</th>\n",
       "      <td>704338227495305216</td>\n",
       "      <td>childhood crush since forever &lt;URL&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>childhood crush since forever</td>\n",
       "      <td>[childhood, crush, forever]</td>\n",
       "      <td>childhood crush forever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12842</th>\n",
       "      <td>60350088769314816</td>\n",
       "      <td>just woke up now its time to do some history</td>\n",
       "      <td>0</td>\n",
       "      <td>just woke up now its time to do some history</td>\n",
       "      <td>[wake, time, history]</td>\n",
       "      <td>wake time history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50525</th>\n",
       "      <td>567154070348382208</td>\n",
       "      <td>once i make it it's only gonna be my day &lt;NUMBER&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>once i make it it's only gonna be my day</td>\n",
       "      <td>[I, day]</td>\n",
       "      <td>I day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115181</th>\n",
       "      <td>920069864487710721</td>\n",
       "      <td>california fire survivors respond unexpectedly...</td>\n",
       "      <td>1</td>\n",
       "      <td>california fire survivors respond unexpectedly...</td>\n",
       "      <td>[california, fire, survivor, respond, unexpect...</td>\n",
       "      <td>fire survivor respond unexpectedly loss home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68047</th>\n",
       "      <td>'511429153090854913'</td>\n",
       "      <td>donation to the victims of hurricane odile via...</td>\n",
       "      <td>1</td>\n",
       "      <td>donation to the victims of hurricane odile via...</td>\n",
       "      <td>[donation, victim, hurricane, odile, mexico, i...</td>\n",
       "      <td>donation victim hurricane odile facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75346</th>\n",
       "      <td>386187778586705920</td>\n",
       "      <td>cuban case is poster child for a more aggressi...</td>\n",
       "      <td>0</td>\n",
       "      <td>cuban case is poster child for a more aggressi...</td>\n",
       "      <td>[cuban, case, poster, child, aggressive, sec, ...</td>\n",
       "      <td>case poster child aggressive therichgetricher ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61600</th>\n",
       "      <td>930464972076969984</td>\n",
       "      <td>can i buy you a drink?not you your dog</td>\n",
       "      <td>0</td>\n",
       "      <td>can i buy you a drink?not you your dog</td>\n",
       "      <td>[I, buy, dog]</td>\n",
       "      <td>I buy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86071</th>\n",
       "      <td>592593388341305345</td>\n",
       "      <td>nepal can't rebuild without the world's help</td>\n",
       "      <td>1</td>\n",
       "      <td>nepal can't rebuild without the world's help</td>\n",
       "      <td>[nepal, rebuild, world, help]</td>\n",
       "      <td>nepal rebuild world help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89230</th>\n",
       "      <td>591915397986779136</td>\n",
       "      <td>m &lt;NUMBER&gt; nepal qk: usgs shakemap prediction ...</td>\n",
       "      <td>1</td>\n",
       "      <td>m  nepal qk: usgs shakemap prediction updated....</td>\n",
       "      <td>[m, nepal, qk, usgs, shakemap, prediction, upd...</td>\n",
       "      <td>m nepal qk usgs shakemap prediction update str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81994</th>\n",
       "      <td>302676378157977601</td>\n",
       "      <td>&lt;URL&gt; haha \u0001 &lt;REPEAT&gt; . this makes myself laug...</td>\n",
       "      <td>1</td>\n",
       "      <td>haha \u0001  . this makes myself laugh  russianmeteor</td>\n",
       "      <td>[haha, laugh, russianmeteor]</td>\n",
       "      <td>haha laugh russianmeteor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25216</th>\n",
       "      <td>921103225490731008</td>\n",
       "      <td>&lt;USER&gt; iran police calling it \"ar \u0001 &lt;REPEAT&gt; i...</td>\n",
       "      <td>0</td>\n",
       "      <td>iran police calling it \"ar \u0001  ian gulf\" on st...</td>\n",
       "      <td>[iran, police, ar, ian, gulf, state, tv, educate]</td>\n",
       "      <td>police educate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49333</th>\n",
       "      <td>1027708885015191552</td>\n",
       "      <td>baker mayfield is about to sneak in that start...</td>\n",
       "      <td>0</td>\n",
       "      <td>baker mayfield is about to sneak in that start...</td>\n",
       "      <td>[baker, mayfield, sneak, start, role]</td>\n",
       "      <td>sneak start role</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139486</th>\n",
       "      <td>396406489617031169</td>\n",
       "      <td>according to &lt;USER&gt; @cbsnews has obtained a ph...</td>\n",
       "      <td>1</td>\n",
       "      <td>according to  @cbsnews has obtained a photo of...</td>\n",
       "      <td>[accord, obtain, photo, paul, ciancia, lax, sh...</td>\n",
       "      <td>accord obtain photo lax shooting suspect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id  \\\n",
       "92200     646397350827659264   \n",
       "92575     846820975069024256   \n",
       "135022     74285979787202560   \n",
       "97707   '348978138795098113'   \n",
       "152965    458355813200183296   \n",
       "52628   '324747652124266496'   \n",
       "99608   '348952324741402625'   \n",
       "65469     704338227495305216   \n",
       "12842      60350088769314816   \n",
       "50525     567154070348382208   \n",
       "115181    920069864487710721   \n",
       "68047   '511429153090854913'   \n",
       "75346     386187778586705920   \n",
       "61600     930464972076969984   \n",
       "86071     592593388341305345   \n",
       "89230     591915397986779136   \n",
       "81994     302676378157977601   \n",
       "25216     921103225490731008   \n",
       "49333    1027708885015191552   \n",
       "139486    396406489617031169   \n",
       "\n",
       "                                                     text  relevance  \\\n",
       "92200   –ø–æ—Å–≤—è—â–∞—é <NUMBER> @comrinru@tommofuckhazza@ana...          0   \n",
       "92575   <USER> good evening, ma. couldn't get the fee ...          0   \n",
       "135022  <USER> oh, and i need to get some more money \u0001...          0   \n",
       "97707   <HASHTAG> mhflood update - audio director of e...          1   \n",
       "152965  people üë´ who are so quick üí®üí® to walk away üêæ <S...          0   \n",
       "52628   explosion at texas fertiliser plant: dozens of...          1   \n",
       "99608   cleaning your flooded house? tips to stay safe...          1   \n",
       "65469                 childhood crush since forever <URL>          0   \n",
       "12842        just woke up now its time to do some history          0   \n",
       "50525   once i make it it's only gonna be my day <NUMBER>          0   \n",
       "115181  california fire survivors respond unexpectedly...          1   \n",
       "68047   donation to the victims of hurricane odile via...          1   \n",
       "75346   cuban case is poster child for a more aggressi...          0   \n",
       "61600              can i buy you a drink?not you your dog          0   \n",
       "86071        nepal can't rebuild without the world's help          1   \n",
       "89230   m <NUMBER> nepal qk: usgs shakemap prediction ...          1   \n",
       "81994   <URL> haha \u0001 <REPEAT> . this makes myself laug...          1   \n",
       "25216   <USER> iran police calling it \"ar \u0001 <REPEAT> i...          0   \n",
       "49333   baker mayfield is about to sneak in that start...          0   \n",
       "139486  according to <USER> @cbsnews has obtained a ph...          1   \n",
       "\n",
       "                                               text_clean  \\\n",
       "92200   –ø–æ—Å–≤—è—â–∞—é  @comrinru@tommofuckhazza@anastasia  ...   \n",
       "92575    good evening, ma. couldn't get the fee from a...   \n",
       "135022   oh, and i need to get some more money \u0001  that...   \n",
       "97707    mhflood update - audio director of emergency ...   \n",
       "152965  people üë´ who are so quick üí®üí® to walk away üêæ  \u0001...   \n",
       "52628   explosion at texas fertiliser plant: dozens of...   \n",
       "99608   cleaning your flooded house? tips to stay safe...   \n",
       "65469                      childhood crush since forever    \n",
       "12842        just woke up now its time to do some history   \n",
       "50525           once i make it it's only gonna be my day    \n",
       "115181  california fire survivors respond unexpectedly...   \n",
       "68047   donation to the victims of hurricane odile via...   \n",
       "75346   cuban case is poster child for a more aggressi...   \n",
       "61600              can i buy you a drink?not you your dog   \n",
       "86071        nepal can't rebuild without the world's help   \n",
       "89230   m  nepal qk: usgs shakemap prediction updated....   \n",
       "81994    haha \u0001  . this makes myself laugh  russianmeteor   \n",
       "25216    iran police calling it \"ar \u0001  ian gulf\" on st...   \n",
       "49333   baker mayfield is about to sneak in that start...   \n",
       "139486  according to  @cbsnews has obtained a photo of...   \n",
       "\n",
       "                                                   lemmas  \\\n",
       "92200                                    [–ø–æ—Å–≤—è—â–∞—é, dash]   \n",
       "92575     [good, evening, ma, fee, private, clinic, luth]   \n",
       "135022                         [oh, I, need, money, good]   \n",
       "97707   [mhflood, update, audio, director, emergency, ...   \n",
       "152965          [people, quick, walk, away, intend, stay]   \n",
       "52628   [explosion, texas, fertiliser, plant, dozen, p...   \n",
       "99608   [clean, flood, house, tip, stay, safe, healthy...   \n",
       "65469                         [childhood, crush, forever]   \n",
       "12842                               [wake, time, history]   \n",
       "50525                                            [I, day]   \n",
       "115181  [california, fire, survivor, respond, unexpect...   \n",
       "68047   [donation, victim, hurricane, odile, mexico, i...   \n",
       "75346   [cuban, case, poster, child, aggressive, sec, ...   \n",
       "61600                                       [I, buy, dog]   \n",
       "86071                       [nepal, rebuild, world, help]   \n",
       "89230   [m, nepal, qk, usgs, shakemap, prediction, upd...   \n",
       "81994                        [haha, laugh, russianmeteor]   \n",
       "25216   [iran, police, ar, ian, gulf, state, tv, educate]   \n",
       "49333               [baker, mayfield, sneak, start, role]   \n",
       "139486  [accord, obtain, photo, paul, ciancia, lax, sh...   \n",
       "\n",
       "                                               text_lemma  \n",
       "92200                                                dash  \n",
       "92575             good evening ma fee private clinic luth  \n",
       "135022                               oh I need money good  \n",
       "97707   update audio director emergency management sou...  \n",
       "152965                 people quick walk away intend stay  \n",
       "52628   explosion fertiliser plant people report injur...  \n",
       "99608   clean flood house tip stay safe healthy abfloo...  \n",
       "65469                             childhood crush forever  \n",
       "12842                                   wake time history  \n",
       "50525                                               I day  \n",
       "115181       fire survivor respond unexpectedly loss home  \n",
       "68047            donation victim hurricane odile facebook  \n",
       "75346   case poster child aggressive therichgetricher ...  \n",
       "61600                                           I buy dog  \n",
       "86071                            nepal rebuild world help  \n",
       "89230   m nepal qk usgs shakemap prediction update str...  \n",
       "81994                            haha laugh russianmeteor  \n",
       "25216                                      police educate  \n",
       "49333                                    sneak start role  \n",
       "139486           accord obtain photo lax shooting suspect  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../data/preprocess_train_dimbat_1.pkl\")\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 163718 entries, 0 to 163717\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   id          160958 non-null  object\n",
      " 1   text        163718 non-null  object\n",
      " 2   relevance   163718 non-null  int64 \n",
      " 3   text_clean  163718 non-null  object\n",
      " 4   lemmas      163718 non-null  object\n",
      " 5   text_lemma  163718 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuxu/neuefische/NLPower-capstone-project/.venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "RSEED = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text_lemma'], df['relevance'], test_size=0.2, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "dd = {'train':Dataset.from_dict({'text':X_train,'label':y_train}),\n",
    "        'test':Dataset.from_dict({'text':X_test,'label':y_test})\n",
    "       }\n",
    "data = DatasetDict(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (130974, 2), 'test': (32744, 2)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'release image suspect terrorist relation bombing drone htt',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 131/131 [00:01<00:00, 75.39ba/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:00<00:00, 77.45ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_tweet = data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (130974, 4), 'test': (32744, 4)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'release image suspect terrorist relation bombing drone htt',\n",
       " 'label': 1,\n",
       " 'input_ids': [101,\n",
       "  2713,\n",
       "  3746,\n",
       "  8343,\n",
       "  9452,\n",
       "  7189,\n",
       "  8647,\n",
       "  18465,\n",
       "  1044,\n",
       "  4779,\n",
       "  102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweet['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 12:39:08.341550: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-08-01 12:39:08.341926: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "tf_train_set = tokenized_tweet[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\"],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_validation_set = tokenized_tweet[\"test\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\"],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=({'input_ids': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 16\n",
    "num_epochs = 5\n",
    "batches_per_epoch = len(tokenized_tweet[\"train\"]) // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'vocab_layer_norm', 'vocab_transform', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'dropout_19', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'vocab_layer_norm', 'vocab_transform', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_39', 'pre_classifier', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "model_bert = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model_bert.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    metrics=tf.metrics.SparseCategoricalAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 12:39:53.220672: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-08-01 12:39:57.606404: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8186/8186 [==============================] - ETA: 0s - loss: 0.1949 - sparse_categorical_accuracy: 0.9296"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 22:09:14.605026: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8186/8186 [==============================] - 34841s 4s/step - loss: 0.1949 - sparse_categorical_accuracy: 0.9296 - val_loss: 0.1786 - val_sparse_categorical_accuracy: 0.9362\n",
      "Epoch 2/2\n",
      "8186/8186 [==============================] - 103064s 13s/step - loss: 0.1400 - sparse_categorical_accuracy: 0.9516 - val_loss: 0.1995 - val_sparse_categorical_accuracy: 0.9324\n"
     ]
    }
   ],
   "source": [
    "history = model_bert.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bert.save_pretrained(\"../models/dimbat_disaster_distilbert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../models/dimbat_disaster_distilbert_model were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at ../models/dimbat_disaster_distilbert_model and are newly initialized: ['dropout_59']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tf_model = TFAutoModelForSequenceClassification.from_pretrained(\"../models/dimbat_disaster_distilbert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"WHO alert over 10000000 monkeypox cases over the world\"\n",
    "input_text_tokenized = tokenizer.encode(input_text,\n",
    "                                        truncation=True,\n",
    "                                        return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction probs are:\n",
      "not disater:  0.22179396   disaster:  0.77820605\n"
     ]
    }
   ],
   "source": [
    "pred_label = tf_model(input_text_tokenized)\n",
    "pre_log = pred_label[0]\n",
    "pre_probs = tf.nn.softmax(pre_log, axis=1).numpy()\n",
    "print('The prediction probs are:')\n",
    "print('not disater: ', pre_probs[0][0], '  disaster: ', pre_probs[0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ed77dcdc7fbab6e38ae64c11601ec4b27d0c7090c2e616cfa30746b20795a2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
