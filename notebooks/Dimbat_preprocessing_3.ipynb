{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ujson as json\n",
    "\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "from textatistic import Textatistic\n",
    "\n",
    "import spacy\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RSEED = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "stopwords = spacy.lang.en.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    doc = nlp(text, disable=['ner', 'parser'])\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    a_lemmas = [lemma for lemma in lemmas \n",
    "              if lemma.isalpha() and lemma not in stopwords]\n",
    "    return a_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_entities(text):\n",
    "    doc = nlp(text)\n",
    "    return(\" \".join([ent.text for ent in doc if not ent.ent_type_]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    html = re.compile(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    return html.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ebola(text):\n",
    "    words = re.compile('(\\s*)ebola(\\s*)')\n",
    "    return words.sub(r\" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mers(text):\n",
    "    words = re.compile('(\\s*)mers(\\s*)')\n",
    "    return words.sub(r\" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_helicopter(text):\n",
    "    words = re.compile('(\\s*)helicopter(\\s*)')\n",
    "    return words.sub(r\" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_train(text):\n",
    "    words = re.compile('(\\s*)train(\\s*)')\n",
    "    return words.sub(r\" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"../data_dimbat/incident-tweets/\"\n",
    "files = os.listdir(path)\n",
    "df_list = list()\n",
    "for file in files:\n",
    "    records = map(json.loads, open(os.path.join(path, file), encoding=\"utf8\"))\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    df[\"text_clean\"] = df[\"text\"].apply(lambda x: remove_html(x))\n",
    "    df['lemmas'] = df['text_clean'].apply(preprocess)   \n",
    "    df[\"text_lemma\"] = [' '.join(map(str, x)) for x in df[\"lemmas\"]]\n",
    "    df['text_lemma'] = df['text_lemma'].apply(remove_entities)\n",
    "    df_list.append(df)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findWholeWord(w):\n",
    "    return re.compile(r'\\b({0})\\b'.format(w), flags=re.IGNORECASE).search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(files)):\n",
    "    if findWholeWord('ebola')(files[i]):\n",
    "        df_list[i]['text_lemma'] = df_list[i]['text_lemma'].apply(remove_ebola)\n",
    "    elif findWholeWord('mers')(files[i]):\n",
    "        df_list[i]['text_lemma'] = df_list[i]['text_lemma'].apply(remove_mers)\n",
    "    elif findWholeWord('helicopter')(files[i]):\n",
    "        df_list[i]['text_lemma'] = df_list[i]['text_lemma'].apply(remove_helicopter)\n",
    "    elif findWholeWord('train')(files[i]):\n",
    "        df_list[i]['text_lemma'] = df_list[i]['text_lemma'].apply(remove_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_2011 = list()\n",
    "index_2012 = list()\n",
    "index_2013 = list()\n",
    "index_2014 = list()\n",
    "index_2015 = list()\n",
    "index_2016 = list()\n",
    "index_2017 = list()\n",
    "index_2018 = list()\n",
    "\n",
    "for i in range(len(files)):\n",
    "    if findWholeWord('2011')(files[i]):\n",
    "        index_2011.append(i)\n",
    "    elif findWholeWord('2012')(files[i]):\n",
    "        index_2012.append(i)\n",
    "    elif findWholeWord('2013')(files[i]):\n",
    "        index_2013.append(i)\n",
    "    elif findWholeWord('2014')(files[i]):\n",
    "        index_2014.append(i)\n",
    "    elif findWholeWord('2015')(files[i]):\n",
    "        index_2015.append(i)\n",
    "    elif findWholeWord('2016')(files[i]):\n",
    "        index_2016.append(i)\n",
    "    elif findWholeWord('2017')(files[i]):\n",
    "        index_2017.append(i)\n",
    "    elif findWholeWord('2018')(files[i]):\n",
    "        index_2018.append(i)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2012 = df_list[index_2012[0]]\n",
    "for i in range(1, len(index_2012)):\n",
    "   df_2012 = df_2012.append(df_list[index_2012[i]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18432 entries, 0 to 18431\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          17548 non-null  object\n",
      " 1   text        18432 non-null  object\n",
      " 2   relevance   18432 non-null  int64 \n",
      " 3   text_clean  18432 non-null  object\n",
      " 4   lemmas      18432 non-null  object\n",
      " 5   text_lemma  18432 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 864.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_2012.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013 = df_list[index_2013[0]]\n",
    "for i in range(1, len(index_2013)):\n",
    "   df_2013 = df_2013.append(df_list[index_2013[i]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70626 entries, 0 to 70625\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          70626 non-null  object\n",
      " 1   text        70626 non-null  object\n",
      " 2   relevance   70626 non-null  int64 \n",
      " 3   text_clean  70626 non-null  object\n",
      " 4   lemmas      70626 non-null  object\n",
      " 5   text_lemma  70626 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_2013.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014 = df_list[index_2014[0]]\n",
    "for i in range(1, len(index_2014)):\n",
    "   df_2014 = df_2014.append(df_list[index_2014[i]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22496 entries, 0 to 22495\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          22496 non-null  object\n",
      " 1   text        22496 non-null  object\n",
      " 2   relevance   22496 non-null  int64 \n",
      " 3   text_clean  22496 non-null  object\n",
      " 4   lemmas      22496 non-null  object\n",
      " 5   text_lemma  22496 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_2014.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2011 = df_list[index_2011[0]]\n",
    "for i in range(1, len(index_2011)):\n",
    "   df_2011 = df_2011.append(df_list[index_2011[i]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3752 entries, 0 to 3751\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          1876 non-null   object\n",
      " 1   text        3752 non-null   object\n",
      " 2   relevance   3752 non-null   int64 \n",
      " 3   text_clean  3752 non-null   object\n",
      " 4   lemmas      3752 non-null   object\n",
      " 5   text_lemma  3752 non-null   object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 176.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_2011.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015 = df_list[index_2015[0]]\n",
    "for i in range(1, len(index_2015)):\n",
    "   df_2015 = df_2015.append(df_list[index_2015[i]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9816 entries, 0 to 9815\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          9816 non-null   object\n",
      " 1   text        9816 non-null   object\n",
      " 2   relevance   9816 non-null   int64 \n",
      " 3   text_clean  9816 non-null   object\n",
      " 4   lemmas      9816 non-null   object\n",
      " 5   text_lemma  9816 non-null   object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 460.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_2015.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = df_list[index_2017[0]]\n",
    "for i in range(1, len(index_2017)):\n",
    "   df_2017 = df_2017.append(df_list[index_2017[i]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28004 entries, 0 to 28003\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          28004 non-null  object\n",
      " 1   text        28004 non-null  object\n",
      " 2   relevance   28004 non-null  int64 \n",
      " 3   text_clean  28004 non-null  object\n",
      " 4   lemmas      28004 non-null  object\n",
      " 5   text_lemma  28004 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = df_list[index_2018[0]]\n",
    "for i in range(1, len(index_2018)):\n",
    "   df_2018 = df_2018.append(df_list[index_2018[i]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10592 entries, 0 to 10591\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          10592 non-null  object\n",
      " 1   text        10592 non-null  object\n",
      " 2   relevance   10592 non-null  int64 \n",
      " 3   text_clean  10592 non-null  object\n",
      " 4   lemmas      10592 non-null  object\n",
      " 5   text_lemma  10592 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 496.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_2018.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2011.to_pickle(\"../data/preprocess_train_dimbat_2011.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2012.to_pickle(\"../data/preprocess_train_dimbat_2012.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013.to_pickle(\"../data/preprocess_train_dimbat_2013.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014.to_pickle(\"../data/preprocess_train_dimbat_2014.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015.to_pickle(\"../data/preprocess_train_dimbat_2015.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017.to_pickle(\"../data/preprocess_train_dimbat_2017.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018.to_pickle(\"../data/preprocess_train_dimbat_2018.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "0ed77dcdc7fbab6e38ae64c11601ec4b27d0c7090c2e616cfa30746b20795a2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
