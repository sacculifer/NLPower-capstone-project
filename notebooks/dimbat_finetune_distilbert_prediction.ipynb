{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>relevance</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>text_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>None</td>\n",
       "      <td>thank you all for your responses to my countle...</td>\n",
       "      <td>1</td>\n",
       "      <td>thank you all for your responses to my countle...</td>\n",
       "      <td>[thank, response, countless, tweet, twitpic, j...</td>\n",
       "      <td>thank response countless tweet devastation har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>60350187654217728</td>\n",
       "      <td>&lt;USER&gt; an apartment? hope there's room for the...</td>\n",
       "      <td>0</td>\n",
       "      <td>an apartment? hope there's room for the bike \u0001</td>\n",
       "      <td>[apartment, hope, room, bike]</td>\n",
       "      <td>apartment hope room bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>None</td>\n",
       "      <td>severe thunderstorm \u0001 &lt;REPEAT&gt; tornado warning...</td>\n",
       "      <td>1</td>\n",
       "      <td>severe thunderstorm \u0001  tornado warning \u0001  the ...</td>\n",
       "      <td>[severe, thunderstorm, tornado, warn, weather,...</td>\n",
       "      <td>severe thunderstorm tornado warn weather roll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>459433811806154752</td>\n",
       "      <td>&lt;USER&gt; @southwestair be glad it's not @british...</td>\n",
       "      <td>0</td>\n",
       "      <td>@southwestair be glad it's not @britishairways</td>\n",
       "      <td>[glad]</td>\n",
       "      <td>glad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>None</td>\n",
       "      <td>yea now we're under a tornado warning. this is...</td>\n",
       "      <td>1</td>\n",
       "      <td>yea now we're under a tornado warning. this is...</td>\n",
       "      <td>[yea, tornado, warn, exhaust]</td>\n",
       "      <td>yea tornado warn exhaust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                               text  \\\n",
       "729                 None  thank you all for your responses to my countle...   \n",
       "2636   60350187654217728  <USER> an apartment? hope there's room for the...   \n",
       "875                 None  severe thunderstorm \u0001 <REPEAT> tornado warning...   \n",
       "2254  459433811806154752  <USER> @southwestair be glad it's not @british...   \n",
       "1589                None  yea now we're under a tornado warning. this is...   \n",
       "\n",
       "      relevance                                         text_clean  \\\n",
       "729           1  thank you all for your responses to my countle...   \n",
       "2636          0    an apartment? hope there's room for the bike \u0001    \n",
       "875           1  severe thunderstorm \u0001  tornado warning \u0001  the ...   \n",
       "2254          0     @southwestair be glad it's not @britishairways   \n",
       "1589          1  yea now we're under a tornado warning. this is...   \n",
       "\n",
       "                                                 lemmas  \\\n",
       "729   [thank, response, countless, tweet, twitpic, j...   \n",
       "2636                      [apartment, hope, room, bike]   \n",
       "875   [severe, thunderstorm, tornado, warn, weather,...   \n",
       "2254                                             [glad]   \n",
       "1589                      [yea, tornado, warn, exhaust]   \n",
       "\n",
       "                                             text_lemma  \n",
       "729   thank response countless tweet devastation har...  \n",
       "2636                           apartment hope room bike  \n",
       "875   severe thunderstorm tornado warn weather roll ...  \n",
       "2254                                               glad  \n",
       "1589                           yea tornado warn exhaust  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../data/preprocess_train_dimbat_2011.pkl\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3752 entries, 0 to 3751\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          1876 non-null   object\n",
      " 1   text        3752 non-null   object\n",
      " 2   relevance   3752 non-null   int64 \n",
      " 3   text_clean  3752 non-null   object\n",
      " 4   lemmas      3752 non-null   object\n",
      " 5   text_lemma  3752 non-null   object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 176.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = list(df[\"text_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "#tf_model = TFAutoModelForSequenceClassification.from_pretrained(\"../models/dimbat_disaster_distilbert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at sacculifer/dimbat_disaster_distilbert were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at sacculifer/dimbat_disaster_distilbert and are newly initialized: ['dropout_39']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sacculifer/dimbat_disaster_distilbert\")\n",
    "\n",
    "tf_model = TFAutoModelForSequenceClassification.from_pretrained(\"sacculifer/dimbat_disaster_distilbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"text-classification\", tokenizer=tokenizer, model=tf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = classifier(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.get_dummies(d[\"label\"] for d in output)[\"LABEL_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1804   72]\n",
      " [   4 1872]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1876\n",
      "           1       0.96      1.00      0.98      1876\n",
      "\n",
      "    accuracy                           0.98      3752\n",
      "   macro avg       0.98      0.98      0.98      3752\n",
      "weighted avg       0.98      0.98      0.98      3752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(df[\"relevance\"], y_pred))\n",
    "print(classification_report(df[\"relevance\"], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"predict\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>relevance</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>text_lemma</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2821</th>\n",
       "      <td>960637525483192320</td>\n",
       "      <td>&lt;USER&gt; reb is a cmb anti too</td>\n",
       "      <td>0</td>\n",
       "      <td>reb is a cmb anti too</td>\n",
       "      <td>[reb, cmb, anti]</td>\n",
       "      <td>reb cmb anti</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>None</td>\n",
       "      <td>&lt;USER&gt; pretty good lady. we are under a tornad...</td>\n",
       "      <td>1</td>\n",
       "      <td>pretty good lady. we are under a tornado watc...</td>\n",
       "      <td>[pretty, good, lady, tornado, watch, finger, c...</td>\n",
       "      <td>pretty good lady tornado watch finger cross</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>748364654783664128</td>\n",
       "      <td>i swear ðŸ˜‚ &lt;URL&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>i swear ðŸ˜‚</td>\n",
       "      <td>[I, swear]</td>\n",
       "      <td>I swear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>None</td>\n",
       "      <td>jeff piotrowski has been streaming live \"chase...</td>\n",
       "      <td>1</td>\n",
       "      <td>jeff piotrowski has been streaming live \"chase...</td>\n",
       "      <td>[jeff, piotrowski, stream, live, chasercam, to...</td>\n",
       "      <td>stream live near intense time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>771893014516072448</td>\n",
       "      <td>&lt;USER&gt; &lt;URL&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>436537863296266240</td>\n",
       "      <td>get da hottest mag out now &lt;USER&gt; issue &lt;HASHT...</td>\n",
       "      <td>0</td>\n",
       "      <td>get da hottest mag out now  issue   with   cli...</td>\n",
       "      <td>[da, hot, mag, issue, click]</td>\n",
       "      <td>da hot mag issue click</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>556277494987644928</td>\n",
       "      <td>that was a dick move</td>\n",
       "      <td>0</td>\n",
       "      <td>that was a dick move</td>\n",
       "      <td>[dick]</td>\n",
       "      <td>dick</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>None</td>\n",
       "      <td>tornado warning for tarrant county. storm spot...</td>\n",
       "      <td>1</td>\n",
       "      <td>tornado warning for tarrant county. storm spot...</td>\n",
       "      <td>[tornado, warn, tarrant, county, storm, spotte...</td>\n",
       "      <td>tornado warn storm spotter report funnel cloud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>60349981055389696</td>\n",
       "      <td>another tuesday night &lt;USER&gt; another few hours...</td>\n",
       "      <td>0</td>\n",
       "      <td>another tuesday night  another few hours shave...</td>\n",
       "      <td>[tuesday, night, hour, shave, end, life, I, pr...</td>\n",
       "      <td>shave end life I probably enjoy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>53599003803254784</td>\n",
       "      <td>you cant rap or sing \u0001 &lt;REPEAT&gt; but yet you al...</td>\n",
       "      <td>0</td>\n",
       "      <td>you cant rap or sing \u0001  but yet you always cre...</td>\n",
       "      <td>[rap, sing, create, song, goo, ou]</td>\n",
       "      <td>rap sing create song goo ou</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                               text  \\\n",
       "2821  960637525483192320                       <USER> reb is a cmb anti too   \n",
       "1510                None  <USER> pretty good lady. we are under a tornad...   \n",
       "2466  748364654783664128                                    i swear ðŸ˜‚ <URL>   \n",
       "479                 None  jeff piotrowski has been streaming live \"chase...   \n",
       "3583  771893014516072448                                       <USER> <URL>   \n",
       "3184  436537863296266240  get da hottest mag out now <USER> issue <HASHT...   \n",
       "2359  556277494987644928                               that was a dick move   \n",
       "21                  None  tornado warning for tarrant county. storm spot...   \n",
       "3252   60349981055389696  another tuesday night <USER> another few hours...   \n",
       "2292   53599003803254784  you cant rap or sing \u0001 <REPEAT> but yet you al...   \n",
       "\n",
       "      relevance                                         text_clean  \\\n",
       "2821          0                              reb is a cmb anti too   \n",
       "1510          1   pretty good lady. we are under a tornado watc...   \n",
       "2466          0                                         i swear ðŸ˜‚    \n",
       "479           1  jeff piotrowski has been streaming live \"chase...   \n",
       "3583          0                                                      \n",
       "3184          0  get da hottest mag out now  issue   with   cli...   \n",
       "2359          0                               that was a dick move   \n",
       "21            1  tornado warning for tarrant county. storm spot...   \n",
       "3252          0  another tuesday night  another few hours shave...   \n",
       "2292          0  you cant rap or sing \u0001  but yet you always cre...   \n",
       "\n",
       "                                                 lemmas  \\\n",
       "2821                                   [reb, cmb, anti]   \n",
       "1510  [pretty, good, lady, tornado, watch, finger, c...   \n",
       "2466                                         [I, swear]   \n",
       "479   [jeff, piotrowski, stream, live, chasercam, to...   \n",
       "3583                                                 []   \n",
       "3184                       [da, hot, mag, issue, click]   \n",
       "2359                                             [dick]   \n",
       "21    [tornado, warn, tarrant, county, storm, spotte...   \n",
       "3252  [tuesday, night, hour, shave, end, life, I, pr...   \n",
       "2292                 [rap, sing, create, song, goo, ou]   \n",
       "\n",
       "                                             text_lemma  predict  \n",
       "2821                                       reb cmb anti        0  \n",
       "1510        pretty good lady tornado watch finger cross        1  \n",
       "2466                                            I swear        0  \n",
       "479                       stream live near intense time        1  \n",
       "3583                                                           0  \n",
       "3184                             da hot mag issue click        0  \n",
       "2359                                               dick        0  \n",
       "21    tornado warn storm spotter report funnel cloud...        1  \n",
       "3252                    shave end life I probably enjoy        0  \n",
       "2292                        rap sing create song goo ou        0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_pickle(\"../data/preprocess_train_dimbat_2018_pred.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new = pd.read_pickle(\"../data/preprocess_train_dimbat_2018_pred.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"CDC's concern over England London, Germany Berlin, and Shanghai Monkeypox outbreak and more\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test = classifier(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9833018183708191}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LABEL_1'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbabd5455024c2c873a7d0f55a109ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521093359014406b8cb0ee9b8fc2b810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/829 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ccc1da43aaf418a9375161898ff1a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60fd5470cfe4406c9513793a54b85983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94525a88187b4798a7b49b5ce500fb59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_geo = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597ca214723545cb91d72303037c79b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/413M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_geo = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"ner\", model=model_geo, tokenizer=tokenizer_geo, aggregation_strategy='average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_results = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG',\n",
       "  'score': 0.49982148,\n",
       "  'word': 'CDC',\n",
       "  'start': 0,\n",
       "  'end': 3},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.7980037,\n",
       "  'word': 'England London',\n",
       "  'start': 19,\n",
       "  'end': 33},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.8422159,\n",
       "  'word': 'Germany Berlin',\n",
       "  'start': 35,\n",
       "  'end': 49},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99629694,\n",
       "  'word': 'Shanghai',\n",
       "  'start': 55,\n",
       "  'end': 63}]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_results = pd.DataFrame(ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.499821</td>\n",
       "      <td>CDC</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.798004</td>\n",
       "      <td>England London</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.842216</td>\n",
       "      <td>Germany Berlin</td>\n",
       "      <td>35</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.996297</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_group     score            word  start  end\n",
       "0          ORG  0.499821             CDC      0    3\n",
       "1          LOC  0.798004  England London     19   33\n",
       "2          LOC  0.842216  Germany Berlin     35   49\n",
       "3          LOC  0.996297        Shanghai     55   63"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_loc = ner_results[ner_results[\"entity_group\"] == \"LOC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.798004</td>\n",
       "      <td>England London</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.842216</td>\n",
       "      <td>Germany Berlin</td>\n",
       "      <td>35</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.996297</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_group     score            word  start  end\n",
       "1          LOC  0.798004  England London     19   33\n",
       "2          LOC  0.842216  Germany Berlin     35   49\n",
       "3          LOC  0.996297        Shanghai     55   63"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "England London\n",
      "Germany Berlin\n",
      "Shanghai\n"
     ]
    }
   ],
   "source": [
    "if not ner_loc.empty :\n",
    "  i = 0\n",
    "  for x in ner_loc[\"score\"]:\n",
    "    if x > 0.5:\n",
    "       print(ner_loc[\"word\"].iloc[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9906e229c498497c9c349763504fc2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/313M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer2 = AutoTokenizer.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "demotion_model = AutoModelForSequenceClassification.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier3 = pipeline(\"text-classification\", tokenizer=tokenizer2, model=demotion_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_results = classifier3(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'fear', 'score': 0.9551898241043091}]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ed77dcdc7fbab6e38ae64c11601ec4b27d0c7090c2e616cfa30746b20795a2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
